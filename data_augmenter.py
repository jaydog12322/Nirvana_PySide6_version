import os
import pandas as pd
import numpy as np
from typing import List, Dict
from datetime import datetime
from tqdm import tqdm
from glob import glob

from feature_config import FEATURE_ID_LIST, FEATURE_LABELS


def find_latest_common_stock_file(base_dir="Perm_Data/Tradability"):
    search_path = os.path.join(base_dir, "ì „ì¢…ëª©_ìš°ì„ ì£¼ì œì™¸_List_*.xlsx")
    candidates = glob(search_path)
    if not candidates:
        raise FileNotFoundError("No ì „ì¢…ëª©_ìš°ì„ ì£¼ì œì™¸_List files found.")
    return max(candidates, key=os.path.getmtime)


# ======== CONFIGURABLE PATHS ========
FOREIGN_PARQUET_FOLDER = "ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜_Parquet"
INSTITUTION_PARQUET_FOLDER = "ê¸°ê´€_ìˆœë§¤ìˆ˜_Parquet"
ENHANCED_OUTPUT_BASE = "Enhanced_Data"


# ======== Load ë³´í†µì£¼ ì¢…ëª© ì •ë³´ ========
def load_common_stock_info() -> pd.DataFrame:
    perm_path = find_latest_common_stock_file()
    df = pd.read_excel(perm_path, sheet_name=0)
    df = df[["ì¢…ëª©ì½”ë“œ", "ì¢…ëª©ëª…"]].dropna()
    df["ë³´í†µì£¼ì—¬ë¶€"] = True
    return df


# ======== MAIN FUNCTION ========
def generate_enhanced_dataset(
        input_folder: str,
        output_folder: str,
        strategy_id: str,
        selected_features: List[str],
        save_combined: bool = True,
        progress_callback=None
):
    common_df = load_common_stock_info()
    ì¢…ëª©ëª…_to_ì½”ë“œ = dict(zip(common_df["ì¢…ëª©ëª…"], common_df["ì¢…ëª©ì½”ë“œ"]))
    ë³´í†µì£¼_set = set(common_df["ì¢…ëª©ì½”ë“œ"])

    strategy_folder = os.path.join(output_folder, strategy_id)
    os.makedirs(strategy_folder, exist_ok=True)

    all_dfs = []

    files = sorted([
        f for f in os.listdir(input_folder)
        if f.endswith(".parquet")
    ])

    print(f"Processing {len(files)} files from: {input_folder}")

    for fname in tqdm(files):
        fpath = os.path.join(input_folder, fname)
        try:
            stock_df = pd.read_parquet(fpath)
            stock_code = fname.replace(".parquet", "").split("_")[0]

            print(f"ðŸ” Processing file: {fname} â†’ ì¢…ëª©ì½”ë“œ: {stock_code}")

            if stock_code not in ë³´í†µì£¼_set:
                print(f"âš ï¸ Skipped (not ë³´í†µì£¼): {stock_code}")
                continue

            augmented_df = augment_single_file(
                df=stock_df,
                stock_code=stock_code,
                ì¢…ëª©ëª…_to_ì½”ë“œ=ì¢…ëª©ëª…_to_ì½”ë“œ,
                selected_features=selected_features
            )

            out_path = os.path.join(strategy_folder, fname)
            augmented_df.to_parquet(out_path, index=False)
            all_dfs.append(augmented_df)

        except Exception as e:
            print(f"âŒ Error processing {fname}: {e}")

    if save_combined and all_dfs:
        combined_df = pd.concat(all_dfs, ignore_index=True)
        combined_df.to_parquet(
            os.path.join(strategy_folder, f"Combined_{strategy_id}.parquet"),
            index=False
        )
        print(f"âœ… Combined file saved: {strategy_id}")


# ======== AUGMENTATION ========
def augment_single_file(
        df: pd.DataFrame,
        stock_code: str,
        ì¢…ëª©ëª…_to_ì½”ë“œ: Dict[str, str],
        selected_features: List[str]
) -> pd.DataFrame:
    label_to_id = dict(zip(FEATURE_LABELS, FEATURE_ID_LIST))
    selected_ids = [label_to_id[label] for label in selected_features if label in label_to_id]

    df = df.copy()

    if "ì¼ìž" not in df.columns and "ë‚ ì§œ" in df.columns:
        df.rename(columns={"ë‚ ì§œ": "ì¼ìž"}, inplace=True)

    if "ì¼ìž" not in df.columns:
        raise ValueError("âš ï¸ ë‚ ì§œ/ì¼ìž ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    df["ì¼ìž"] = pd.to_datetime(df["ì¼ìž"])
    df.sort_values("ì¼ìž", inplace=True)
    df.reset_index(drop=True, inplace=True)

    df["ì¢…ëª©ì½”ë“œ"] = stock_code
    df["ë³´í†µì£¼ì—¬ë¶€"] = True

    # Look up ì¢…ëª©ëª… from ì¢…ëª©ëª…_to_ì½”ë“œ
    code_to_name = {v: k for k, v in ì¢…ëª©ëª…_to_ì½”ë“œ.items()}
    df["ì¢…ëª©ëª…"] = code_to_name.get(stock_code, "Unknown")

    if "ê±°ëž˜ëŒ€ê¸ˆ" in selected_ids:
        df["ê±°ëž˜ëŒ€ê¸ˆ"] = ((df["ê³ ê°€"] + df["ì €ê°€"]) / 2) * df["ê±°ëž˜ëŸ‰"]

    # === Precompute MAs if needed for dependent features ===
    required_ma_periods = [5, 10, 20, 60, 120]
    for period in required_ma_periods:
        col = f"MA_{period}"
        if any(sel.startswith(col) or sel.endswith(col) for sel in selected_ids):
            df[col] = df["ì¢…ê°€"].rolling(window=period).mean()

    # ðŸ†• NEW: Calculate Low_MA_5
    if "Low_MA_5" in selected_ids:
        df["Low_MA_5"] = calculate_low_ma_5(df)

    # ðŸ†• NEW: Calculate False_Entry_Checker (FIXED - NOW IMPLEMENTED)
    if "False_Entry_Checker" in selected_ids:
        # First ensure Low_MA_5 exists (calculate it if needed)
        if "Low_MA_5" not in df.columns:
            df["Low_MA_5"] = calculate_low_ma_5(df)

        df["False_Entry_Checker"] = calculate_false_entry_checker(df)

    if "ë“±ë½ë¥ " in selected_ids:
        df["ë“±ë½ë¥ "] = df["ì¢…ê°€"].pct_change().fillna(0) * 100

    for period in required_ma_periods:
        vol_col = f"ê±°ëž˜ëŒ€ê¸ˆ_MA_{period}"
        if vol_col in selected_ids and "ê±°ëž˜ëŒ€ê¸ˆ" in df.columns:
            df[vol_col] = df["ê±°ëž˜ëŒ€ê¸ˆ"].rolling(window=period).mean()

    if "MA5_10_ì°¨ì´ìœ¨" in selected_ids:
        df["MA5_10_ì°¨ì´ìœ¨"] = (df["MA_5"] - df["MA_10"]) / df["MA_10"] * 100

    if "MA10_20_ì°¨ì´ìœ¨" in selected_ids:
        df["MA10_20_ì°¨ì´ìœ¨"] = (df["MA_10"] - df["MA_20"]) / df["MA_20"] * 100

    if "ì •ë°°ì—´ì—¬ë¶€" in selected_ids:
        df["ì •ë°°ì—´ì—¬ë¶€"] = (df["MA_5"] > df["MA_10"]) & (df["MA_10"] > df["MA_20"])

    for period in [5, 10, 20]:
        slope_col = f"MA{period}_Slope"
        if slope_col in selected_ids:
            df[slope_col] = df[f"MA_{period}"].diff()

    if "ê³¨ë“ í¬ë¡œìŠ¤_MA5_20" in selected_ids:
        prev_ma5 = df["MA_5"].shift(1)
        prev_ma20 = df["MA_20"].shift(1)
        df["ê³¨ë“ í¬ë¡œìŠ¤_MA5_20"] = (
                (df["MA_5"] > df["MA_20"]) & (prev_ma5 <= prev_ma20)
        )

    if "ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜" in selected_ids or "ê¸°ê´€_ìˆœë§¤ìˆ˜" in selected_ids:
        combined_dir = "Combined_ìˆœë§¤ìˆ˜_Parquet"

        try:
            latest_foreign = max([
                f for f in os.listdir(combined_dir)
                if f.startswith("Combined_ì™¸êµ­ì¸ìˆœë§¤ìˆ˜_")
            ])
            foreign_df = pd.read_parquet(os.path.join(combined_dir, latest_foreign))
            foreign_df["ì¼ìž"] = pd.to_datetime(foreign_df["ì¼ìž"])
        except Exception as e:
            print(f"âš ï¸ ì™¸êµ­ì¸ íŒŒì¼ ì˜¤ë¥˜: {e}")
            foreign_df = pd.DataFrame()

        try:
            latest_inst = max([
                f for f in os.listdir(combined_dir)
                if f.startswith("Combined_ê¸°ê´€í•©ê³„ìˆœë§¤ìˆ˜_")
            ])
            inst_df = pd.read_parquet(os.path.join(combined_dir, latest_inst))
            inst_df["ì¼ìž"] = pd.to_datetime(inst_df["ì¼ìž"])
        except Exception as e:
            print(f"âš ï¸ ê¸°ê´€ íŒŒì¼ ì˜¤ë¥˜: {e}")
            inst_df = pd.DataFrame()

        if "ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜" in selected_ids and not foreign_df.empty:
            df = df.merge(
                foreign_df[["ì¢…ëª©ì½”ë“œ", "ì¼ìž", "ê±°ëž˜ëŒ€ê¸ˆ_ìˆœë§¤ìˆ˜"]]
                .rename(columns={"ê±°ëž˜ëŒ€ê¸ˆ_ìˆœë§¤ìˆ˜": "ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜"}),
                on=["ì¢…ëª©ì½”ë“œ", "ì¼ìž"], how="left"
            )

        if "ê¸°ê´€_ìˆœë§¤ìˆ˜" in selected_ids and not inst_df.empty:
            df = df.merge(
                inst_df[["ì¢…ëª©ì½”ë“œ", "ì¼ìž", "ê±°ëž˜ëŒ€ê¸ˆ_ìˆœë§¤ìˆ˜"]]
                .rename(columns={"ê±°ëž˜ëŒ€ê¸ˆ_ìˆœë§¤ìˆ˜": "ê¸°ê´€_ìˆœë§¤ìˆ˜"}),
                on=["ì¢…ëª©ì½”ë“œ", "ì¼ìž"], how="left"
            )

        # Clean any duplicated columns from earlier merges
        for col in ["ì™¸êµ­ì¸_ìˆœë§¤ìˆ˜", "ê¸°ê´€_ìˆœë§¤ìˆ˜"]:
            if f"{col}_x" in df.columns and f"{col}_y" in df.columns:
                df.drop(columns=[f"{col}_x"], inplace=True)
                df.rename(columns={f"{col}_y": col}, inplace=True)

    # === Placeholder Simulation Columns ===
    for col in ["MA5_ìµœëŒ€ìƒìŠ¹ë¥ ", "MA10_ìµœëŒ€ìƒìŠ¹ë¥ ", "MDD_ì§„ìž…ì´í›„"]:
        if col in selected_ids:
            df[col] = np.nan
    # === D+1 Open to Close % ===
    if "D+1 Open to Close %" in selected_ids:
        df["D+1 Open to Close %"] = (
                                            (df["ì¢…ê°€"].shift(-1) - df["ì‹œê°€"].shift(-1)) / df["ì‹œê°€"].shift(-1)
                                    ) * 100

    print(f"âœ… Augmented {stock_code} â†’ {df.columns.tolist()}")

    mandatory_columns = [
        "ì¼ìž",
        "ì¢…ëª©ëª…",
        "ì¢…ëª©ì½”ë“œ",
        "ì‹œê°€",
        "ê³ ê°€",
        "ì €ê°€",
        "ì¢…ê°€",
        "ê±°ëž˜ëŸ‰",
        "ì™¸êµ­ì¸ì†Œì§„ìœ¨",
    ]

    final_columns = list(
        dict.fromkeys(
            mandatory_columns
            + [
                col
                for sel in selected_ids
                for col in df.columns
                if col == sel or col.startswith(sel + "_")
            ]
        )
    )

    print(f"[DEBUG] Selected final columns: {final_columns}")
    df = df[final_columns]

    return df


# ðŸ†• NEW FUNCTION: Calculate Low_MA_5
def calculate_low_ma_5(df: pd.DataFrame) -> pd.Series:
    """
    Calculate Low_MA_5: (Close[D-4] + Close[D-3] + Close[D-2] + Close[D-1] + Low[D]) / 5
    """
    result = pd.Series(np.nan, index=df.index)

    for i in range(4, len(df)):  # Start from index 4 (5th row) to have 4 previous days
        # Get previous 4 days' closing prices
        prev_4_closes = df.loc[i - 4:i - 1, "ì¢…ê°€"].values  # [D-4, D-3, D-2, D-1]
        # Get current day's low price
        current_low = df.loc[i, "ì €ê°€"]

        # Calculate: (sum of prev 4 closes + current low) / 5
        if len(prev_4_closes) == 4 and not np.isnan(current_low):
            low_ma_5 = (prev_4_closes.sum() + current_low) / 5
            result.iloc[i] = low_ma_5

    return result


# ðŸ†• NEW FUNCTION: Calculate False_Entry_Checker
def calculate_false_entry_checker(df: pd.DataFrame) -> pd.Series:
    """
    Calculate False_Entry_Checker: Compare Low_MA_5 with ì €ê°€ (Low price)
    - If Low_MA_5 < ì €ê°€: "No_Entry_Made"
    - If Low_MA_5 >= ì €ê°€: "Entry_Made"
    """
    result = pd.Series(np.nan, index=df.index)

    for i in range(len(df)):
        low_ma_5 = df.loc[i, "Low_MA_5"]
        low_price = df.loc[i, "ì €ê°€"]

        # Only calculate if both values are available (not NaN)
        if not pd.isna(low_ma_5) and not pd.isna(low_price):
            if low_ma_5 < low_price:
                result.iloc[i] = "No_Entry_Made"
            else:
                result.iloc[i] = "Entry_Made"

    return result
